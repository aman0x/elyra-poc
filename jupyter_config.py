# Configuration for Elyra's Airflow Pipeline Processor

# Tell Elyra to use modern Airflow operator imports
c.AirflowPipelineProcessor.available_airflow_operators = [
    # Kubernetes operators
    "airflow.providers.cncf.kubernetes.operators.pod.KubernetesPodOperator",
    
    # Kubernetes models
    "kubernetes.client.models.V1Volume",
    "kubernetes.client.models.V1VolumeMount",
    "airflow.providers.cncf.kubernetes.secret.Secret",
    
    # Common operators
    "airflow.providers.standard.operators.bash.BashOperator",
    "airflow.providers.standard.operators.python.PythonOperator",
    "airflow.providers.standard.operators.empty.EmptyOperator",
    
    # Sensors
    "airflow.providers.standard.sensors.filesystem.FileSensor",
    
    # Other useful operators
    "airflow.providers.ssh.operators.ssh.SSHOperator",
    "airflow.providers.http.operators.http.HttpOperator"
]

# Configure Airflow 3.0-specific settings
c.AirflowPipelineProcessor.airflow_runtime_configuration = {
    "airflow_version": "3.0.1",  # Specify the target Airflow version
    "use_pendulum": True,        # Use pendulum instead of days_ago
    "namespace": "airflow-new",  # Default Kubernetes namespace
    "use_k8s_models": True       # Use kubernetes.client.models
}

# Set Airflow DAG generation settings
c.AirflowPipelineProcessor.dag_generation_options = {
    "include_dag_header_comments": True,
    "use_schedule_param": True,  # Use schedule instead of schedule_interval
    "default_timezone": "UTC",
    "start_date_offset_days": 1,
    "generate_airflow3_compatible": True
}

# Customize the Jinja template variables for Airflow 3.0
c.AirflowPipelineProcessor.template_variables = {
    "airflow_import": "from airflow import DAG",
    "datetime_import": "import pendulum",
    "default_args_timezone": "UTC",
    "dag_args_schedule": "schedule",  # Use schedule instead of schedule_interval
    "dag_default_namespace": "airflow-new",
    "dag_processor_annotation": "# Generated by Elyra for Airflow 3.0"
}